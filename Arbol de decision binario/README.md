# üìß Clasificador de SPAM con √Årboles de Decisi√≥n

Este proyecto consiste en un script de Python dise√±ado para construir un **clasificador de correos electr√≥nicos**. Su funci√≥n principal es aprender a diferenciar de forma autom√°tica entre correos leg√≠timos (**HAM**) y correo no deseado (**SPAM**) utilizando un modelo de **√Årbol de Decisi√≥n**.

M√°s all√° de solo entrenar un modelo, el script realiza un an√°lisis completo para evaluar qu√© tan bien funciona, si su rendimiento es estable y cu√°les son los factores que m√°s influyen en sus decisiones. El enfoque principal est√° en el proceso de **ingenier√≠a de caracter√≠sticas o features**, que es la forma de transformar texto simple en informaci√≥n num√©rica que un algoritmo pueda interpretar.

-----

## üéØ Objetivos del Proyecto

  * **Implementar un Clasificador Funcional:** Construir un modelo capaz de recibir un correo y etiquetarlo como SPAM o HAM, utilizando el algoritmo de √Årbol de Decisi√≥n.
  * **Aplicar Ingenier√≠a de Caracter√≠sticas:** Dise√±ar y extraer un conjunto de caracter√≠sticas num√©ricas a partir del texto de los correos, con la hip√≥tesis de que estas contendr√°n las "pistas" que diferencian un correo SPAM de uno leg√≠timo.
  * **Analizar el Rendimiento y la Estabilidad:** No es suficiente que el modelo funcione bien una vez. Se busca comprobar que su rendimiento es consistente a trav√©s de m√∫ltiples pruebas, utilizando m√©tricas est√°ndar como el F1-Score y el Accuracy.
  * **Garantizar la Interpretabilidad:** Uno de los objetivos clave es poder entender y explicar las decisiones del modelo. Se generar√°n visualizaciones para responder preguntas como: ¬øEn qu√© se fija el modelo para clasificar? ¬øQu√© caracter√≠sticas son las m√°s importantes?

-----

## üìä El Dataset: `emails_dataset.csv`

Para entrenar y probar el modelo, se utiliz√≥ un archivo llamado `emails_dataset.csv` que contiene 5000 ejemplos de correos, cada uno con su asunto, cuerpo y una etiqueta que indica si es SPAM o HAM.

### An√°lisis y Consideraciones sobre los Datos

Es fundamental aclarar que este es un **dataset sint√©tico**, es decir, fue generado por una inteligencia artificial (ChatGPT) para este ejercicio. Esto tiene ventajas y desventajas importantes:

  * **Puntos a Favor:**

      * **Ideal para Aprender:** Al ser un dataset "perfecto" (sin errores, datos faltantes o ruido), nos permite concentrarnos 100% en el algoritmo y la creaci√≥n de caracter√≠sticas, sin las distracciones y el trabajo extra que implica la limpieza de datos del mundo real.
      * **Patrones Claros:** Los ejemplos son muy representativos. Los correos SPAM contienen palabras y estructuras muy obvias ("premio", "dinero", "clic aqu√≠"), lo que facilita que el modelo aprenda los patrones b√°sicos de forma efectiva.

  * **Limitaciones Importantes:**

      * **Baja Complejidad:** El SPAM real es mucho m√°s sofisticado. Utiliza sin√≥nimos, im√°genes, caracteres invisibles y otras t√©cnicas para enga√±ar a los filtros. Este dataset no presenta ese nivel de desaf√≠o.
      * **Rendimiento "Optimista":** Es probable que el alto rendimiento obtenido en este proyecto no se replique exactamente con un dataset de correos reales, ya que estos √∫ltimos son mucho m√°s "ruidosos" y complejos.


-----

## üõ†Ô∏è Metodolog√≠a Aplicada

El flujo de trabajo del proyecto se puede dividir en las siguientes etapas:

### 1\. Ingenier√≠a de Caracter√≠sticas (Feature Engineering)

Esta es la fase m√°s creativa y crucial. Un modelo matem√°tico no entiende de ofertas o reuniones, solo de n√∫meros. por ello el trabajo es traducir las ideas y patrones del texto a un formato num√©rico. Para ello, se crearon las siguientes caracter√≠sticas:

  * **Caracter√≠sticas de Estructura y Longitud:**

      * `word_count` y `char_count`: Miden la longitud total del correo. La hip√≥tesis es que los correos SPAM pueden ser anormalmente cortos (para llamar la atenci√≥n r√°pido) o largos (para esconder palabras clave).
      * `avg_word_length`: La longitud promedio de las palabras. A veces, el SPAM usa palabras extra√±as o alargadas.

  * **Caracter√≠sticas de Estilo y Formato (Pistas de SPAM):**

      * `num_exclamations` y `num_uppercase_words`: El SPAM a menudo abusa de las may√∫sculas y los signos de exclamaci√≥n para generar un falso sentido de urgencia o emoci√≥n. Contar su frecuencia es una pista muy √∫til.
      * `num_links`: La mayor√≠a de los correos SPAM tienen un objetivo: que hagas clic en un enlace. Por tanto, la cantidad de URLs es un indicador muy fuerte.
      * `special_char_ratio`: Una alta proporci√≥n de caracteres como `$` `!` `%` `*` suele ser una se√±al de alerta.

  * **Caracter√≠sticas Sem√°nticas (Contenido del Mensaje):**

      * Se crearon tres indicadores binarios (0 si no aparece, 1 si aparece) que buscan la presencia de palabras clave muy espec√≠ficas y de alto impacto:
          * `contains_free`: Busca palabras como "free", "gratis", "win", "premio". 
          * `contains_money`: Busca t√©rminos como "money", "dinero", "$", "inversi√≥n". 
          * `contains_click`: Detecta "llamadas a la acci√≥n" como "click", "clic", "accede", "reclama". 

### 2\. Elecci√≥n del Modelo: ¬øPor qu√© un √Årbol de Decisi√≥n?

Con las caracter√≠sticas ya creadas, se eligi√≥ el `DecisionTreeClassifier` de la librer√≠a Scikit-learn. Esta elecci√≥n no fue al azar y se bas√≥ en tres ventajas clave para este proyecto:

1.  **Interpretabilidad (Es un modelo de "Caja Blanca"):** Esta es su mayor fortaleza. A diferencia de otros modelos m√°s complejos que funcionan como una "caja negra", un √°rbol de decisi√≥n es totalmente transparente. Genera un conjunto de reglas del tipo "si-entonces" que son f√°ciles de leer y entender para un ser humano. Esto nos permite no solo saber *qu√©* predice, sino *por qu√©* lo predice.
2.  **No Requiere Normalizaci√≥n de Datos:** Los √°rboles de decisi√≥n no se ven afectados por la escala de las caracter√≠sticas. Esto significa que podemos usar el `word_count` (cuyos valores pueden ser cientos) junto a `contains_free` (que solo es 0 o 1) sin necesidad de aplicar transformaciones complejas a los datos.
3.  **Rapidez de Entrenamiento:** Es un algoritmo computacionalmente ligero y r√°pido, lo que lo hace perfecto para el siguiente paso: un an√°lisis de estabilidad que requiere entrenar el modelo muchas veces.

### 3\. Experimento de Estabilidad (50 Iteraciones)

Un modelo de Machine Learning puede tener un buen resultado por simple casualidad, dependiendo de qu√© datos se usaron para entrenar y cu√°les para probar. Para asegurarnos de que nuestro clasificador es **estable** y **fiable**, se implement√≥ el siguiente experimento:

1.  Se ejecuta un bucle **50 veces**.
2.  En cada iteraci√≥n, los datos se mezclan y se dividen de una forma aleatoria y diferente (`random_state` cambia en cada ciclo).
3.  Con cada nueva divisi√≥n, se entrena un √°rbol de decisi√≥n desde cero y se eval√∫a su rendimiento con las m√©tricas `F1-Score` y `Accuracy`.
4.  Los resultados de las 50 iteraciones se guardan para luego analizar sus estad√≠sticas (media, desviaci√≥n est√°ndar, etc.).

Este proceso nos da una visi√≥n mucho m√°s realista y robusta de la calidad del modelo, ya que promedia su rendimiento en 50 escenarios diferentes, mitigando el factor suerte.

-----

## üìö Justificaci√≥n de las Librer√≠as Utilizadas

Cada librer√≠a externa cumple un rol fundamental y fue elegida por ser un est√°ndar en el campo de la ciencia de datos.

  * `pandas` y `numpy`: Son la columna vertebral para la manipulaci√≥n de datos en Python. **Pandas** es indispensable para leer el archivo `emails_dataset.csv` y trabajar con los datos en una estructura tabular (DataFrame). **NumPy** proporciona las herramientas para realizar c√°lculos num√©ricos de manera eficiente.
  * `scikit-learn`: Es la librer√≠a de Machine Learning m√°s popular de Python. De ella se utilizan componentes esenciales:
      * `DecisionTreeClassifier`: El algoritmo que implementa el modelo.
      * `train_test_split`: La funci√≥n correcta para dividir los datos en conjuntos de entrenamiento y prueba de forma estratificada, lo que asegura que la proporci√≥n de SPAM/HAM se mantenga en ambas partes.
      * `metrics`: Incluye todas las funciones necesarias para evaluar el modelo, como `f1_score`, `accuracy_score` y `confusion_matrix`.
  * `matplotlib` y `seaborn`: El d√∫o por excelencia para la visualizaci√≥n de datos. **Matplotlib** es la librer√≠a base que permite crear todo tipo de gr√°ficos, mientras que **Seaborn** se construye sobre ella para ofrecer gr√°ficos estad√≠sticos m√°s complejos y con una mejor est√©tica por defecto.
  * `os` y `re`: Son m√≥dulos nativos de Python. `os` se usa para manejar las rutas de los archivos de forma que el script funcione en cualquier sistema operativo. `re` (expresiones regulares) es la herramienta que permite buscar patrones de texto de forma avanzada, siendo clave para detectar las palabras clave en los correos.

-----

## üöÄ C√≥mo Empezar

### Requisitos Previos

Para ejecutar este script, solo necesitas tener **Python 3** instalado, junto con las librer√≠as mencionadas anteriormente.

Puedes instalar todas las dependencias necesarias con un √∫nico comando en tu terminal:

```bash
pip install pandas numpy scikit-learn matplotlib seaborn
```

### Instrucciones de Uso

1.  Clona o descarga este repositorio en tu m√°quina local.
2.  Aseg√∫rate de que el archivo `emails_dataset.csv` se encuentre en la misma carpeta que el script `ArbolBinario.py`.
3.  Abre una terminal, navega hasta la carpeta del proyecto y ejecuta el script con el siguiente comando:
    ```bash
    python ArbolBinario.py
    ```
4.  El script comenzar√° a procesar los datos, entrenar los modelos y generar los gr√°ficos. Al finalizar, imprimir√° un resumen en la consola y todos los gr√°ficos se guardar√°n como archivos `.png` en la misma carpeta.

-----

## üî¨ An√°lisis de los Resultados

El script genera varios gr√°ficos, cada uno dise√±ado para responder una pregunta espec√≠fica sobre el modelo.

  * **Gr√°fico del √Årbol de Decisi√≥n (`arbol_de_decision.png`):** Esta es la visualizaci√≥n m√°s importante para entender el modelo. Muestra, de forma jer√°rquica, las reglas que el √°rbol ha aprendido. Se puede seguir el camino desde la ra√≠z hasta las hojas para ver qu√© preguntas hace el modelo sobre las caracter√≠sticas ("¬øcontiene 'dinero'?", "¬øcu√°ntos enlaces tiene?") para llegar a un veredicto.

  * **Gr√°ficos de Evoluci√≥n (`evolucion_f1_score.png`, `evolucion_accuracy.png`):** Estos gr√°ficos muestran el F1-Score y el Accuracy obtenidos en cada una de las 50 iteraciones. Son clave para evaluar la estabilidad. Una l√≠nea de media alta con una banda sombreada (que representa la desviaci√≥n est√°ndar) muy estrecha, indica que el modelo es robusto y su rendimiento no var√≠a mucho aunque cambien los datos de entrenamiento.

  * **An√°lisis de Z-Score (`zscore_analisis.png`):** El Z-Score nos dice qu√© tan "extra√±o" o "at√≠pico" fue el resultado de una iteraci√≥n en comparaci√≥n con el promedio. Un valor muy alto o muy bajo (generalmente por encima de 2 o por debajo de -2) podr√≠a indicar una divisi√≥n de datos an√≥mala. Este gr√°fico permite confirmar visualmente que la mayor√≠a de las ejecuciones tuvieron un rendimiento dentro de lo esperado.

  * **Distribuci√≥n de M√©tricas (`distribucion_metricas.png`):** Estos histogramas complementan los gr√°ficos de evoluci√≥n. Muestran la frecuencia de cada resultado. Una forma de campana centrada en un valor alto (ej. 0.95) sugiere que el modelo consistentemente alcanza ese nivel de rendimiento.

  * **Matriz de Confusi√≥n (`matriz_confusion.png`):** Esta tabla es fundamental para entender los errores del modelo. Nos dice no solo cu√°ntas veces acert√≥, sino c√≥mo se equivoc√≥:

      * **Verdaderos Positivos/Negativos:** Aciertos correctos.
      * **Falsos Positivos:** El error m√°s grave. Son correos leg√≠timos (HAM) que el modelo clasific√≥ incorrectamente como SPAM.
      * **Falsos Negativos:** Correos SPAM que el modelo no detect√≥ y se colaron en la bandeja de entrada.

  * **Importancia de las Caracter√≠sticas (`importancia_caracteristicas.png`):** Este gr√°fico de barras es, quiz√°s, el m√°s revelador. Responde a la pregunta: "De todo lo que le dimos al modelo, ¬øqu√© le pareci√≥ m√°s √∫til?". Ordena las caracter√≠sticas de mayor a menor importancia, permitiendo validar si las hip√≥tesis iniciales eran correctas. En este caso, confirma que el contenido sem√°ntico (palabras sobre dinero, promociones, etc.) es mucho m√°s decisivo que otras m√©tricas.

-----

## üèÅ Conclusi√≥n

El proyecto cumple con su objetivo de construir un clasificador de SPAM que no solo es funcional, sino tambi√©n **analizable e interpretable**.

El an√°lisis de estabilidad a trav√©s de 50 iteraciones demuestra que el modelo tiene un rendimiento **consistente**, y no es producto de una √∫nica ejecuci√≥n afortunada. Por otro lado, el an√°lisis de importancia de caracter√≠sticas confirma que el modelo ha sido capaz de aprender patrones l√≥gicos y relevantes, priorizando el contenido sem√°ntico de los correos para tomar sus decisiones.
